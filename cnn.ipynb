{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = load(fo, encoding='latin1')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    data = unpickle(f\"data/{filename}\")\n",
    "    df = DataFrame(list(data.items()), columns=[\"Keys\", \"Values\"])\n",
    "    return data, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read labels\n",
    "labels_data, labels_df = read_data(\"batches.meta\")\n",
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels_data[\"label_names\"]\n",
    "all_labels_df = DataFrame(labels, columns=[\"Labels\"])\n",
    "all_labels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1, df1 = read_data(\"data_batch_1\")\n",
    "data2, df2 = read_data(\"data_batch_2\")\n",
    "data3, df3 = read_data(\"data_batch_3\")\n",
    "data4, df4 = read_data(\"data_batch_4\")\n",
    "data5, df5 = read_data(\"data_batch_5\")\n",
    "\n",
    "test_data, test_df = read_data(\"test_batch\")\n",
    "\n",
    "# Combine data\n",
    "dataset = np.concatenate([data1[\"data\"], data2[\"data\"], data3[\"data\"], data4[\"data\"], data5[\"data\"]], axis=0)\n",
    "dataset_labels = np.concatenate([data1[\"labels\"], data2[\"labels\"], data3[\"labels\"], data4[\"labels\"], data5[\"labels\"]], axis=0)\n",
    "\n",
    "print(\"Combined Data Shape:\", dataset.shape)\n",
    "print(\"Combined Labels Length:\", len(dataset_labels))\n",
    "\n",
    "test_dataset = test_data[\"data\"]\n",
    "test_dataset_labels = test_data[\"labels\"]\n",
    "\n",
    "print(\"Test Data Shape: \", test_dataset.shape)\n",
    "print(\"Test Data Labels Length: \", len(test_dataset_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape images while taking channel first then rearrange to height, width, channel\n",
    "dataset = dataset.reshape(len(dataset),3,32,32).transpose(0,2,3,1)    \n",
    "print(dataset.shape)\n",
    "\n",
    "test_dataset = test_dataset.reshape(len(test_dataset),3,32,32).transpose(0,2,3,1)\n",
    "print(test_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_dataset_images(temp_data, temp_labels,images_per_label=10 ):\n",
    "    unique_image_labels = set(temp_labels)\n",
    "\n",
    "    for current_label in unique_image_labels:\n",
    "        # get indices of images with current label\n",
    "        current_label_indices = [current_image_index for current_image_index, current_image_label in enumerate(temp_labels) if current_image_label == current_label]\n",
    "        \n",
    "        current_label_random_indices = random.sample(current_label_indices, images_per_label)\n",
    "        \n",
    "        fig, axes = plt.subplots(1, images_per_label, figsize=(12, 1.5))\n",
    "        fig.suptitle(f\"Label: {labels[current_label]}\")\n",
    "        \n",
    "        for i, index in enumerate(current_label_random_indices):\n",
    "            axes[i].imshow(temp_data[index])\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_dataset_images(dataset, dataset_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_normalized = dataset / 255.0\n",
    "X_test_normalized = test_dataset / 255.0\n",
    "\n",
    "y_train = to_categorical(dataset_labels)\n",
    "y_test = to_categorical(test_dataset_labels)\n",
    "\n",
    "X_train_normalized = np.array(X_train_normalized)\n",
    "X_test_normalized = np.array(X_test_normalized)\n",
    "\n",
    "# create validation set\n",
    "X_train_normalized, X_validation, y_train, y_validation = train_test_split(X_train_normalized, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# print shapes\n",
    "print(\"X_train_normalized shape:\", X_train_normalized.shape)\n",
    "print(\"X_test_normalized shape:\", X_test_normalized.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(\"X_validation shape:\", X_validation.shape)\n",
    "print(\"y_validation shape:\", y_validation.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "\n",
    "# Build the model with additional regularization and optimization techniques\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(512, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(10, activation='softmax', kernel_regularizer=l2(0.001)))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Implement callbacks for early stopping and learning rate reduction\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "datagen.fit(X_train_normalized)\n",
    "\n",
    "# Train the model\n",
    "model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train_normalized, y_train, validation_data=(X_validation, y_validation), epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)  # Add grid lines\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Prediction & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test data\n",
    "test_loss, test_acc = model.evaluate(X_test_normalized, y_test)\n",
    "print(f'Test accuracy: {test_acc * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
